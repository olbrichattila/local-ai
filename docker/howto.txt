- Ollama
ollama.ai
curl -fsSL https://ollama.com/install.sh | sh

ollama pull llama2
# command line prompt to test it: exit with /bye
ollama run llama2

ollama as docker:

docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama



Web UI:
u can use open-webui (https://github.com/open-webui/open-webui)

docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main



